{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Intro/References\" data-toc-modified-id=\"Intro/References-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Intro/References</a></span></li><li><span><a href=\"#Vectorization-is-terrible:\" data-toc-modified-id=\"Vectorization-is-terrible:-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Vectorization is terrible:</a></span></li><li><span><a href=\"#Debugging:\" data-toc-modified-id=\"Debugging:-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Debugging:</a></span></li><li><span><a href=\"#Scaling-not-clipping?\" data-toc-modified-id=\"Scaling-not-clipping?-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Scaling not clipping?</a></span></li><li><span><a href=\"#Pytorch\" data-toc-modified-id=\"Pytorch-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Pytorch</a></span></li><li><span><a href=\"#Pytorch-monitor\" data-toc-modified-id=\"Pytorch-monitor-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Pytorch monitor</a></span><ul class=\"toc-item\"><li><span><a href=\"#Vectorizing-is-terrible/awesome.\" data-toc-modified-id=\"Vectorizing-is-terrible/awesome.-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Vectorizing is terrible/awesome.</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro/References\n",
    "\n",
    "A Distributional Perspective on Reinforcement Learning\n",
    "https://deepmind.com/blog/going-beyond-average-reinforcement-learning/\n",
    "https://arxiv.org/abs/1707.06887\n",
    "\n",
    "Distributional Reinforcement Learning with Quantile Regression\n",
    "https://arxiv.org/abs/1710.10044\n",
    "\n",
    "Distributional RL\n",
    "https://mtomassoli.github.io/2017/12/08/distributional_rl/\n",
    "\n",
    "An Analysis of Categorical Distributional Reinforcement Learning\n",
    "https://arxiv.org/abs/1802.08163\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Scaling not clipping?\n",
    "\n",
    "# Pytorch\n",
    "# Pytorch monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T20:50:30.617186Z",
     "start_time": "2018-07-19T20:50:29.616797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "import math\n",
    "import random\n",
    "\n",
    "import attr\n",
    "import gym\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from pytorch_monitor import init_experiment, monitor_module\n",
    "# from smooth import smooth  # timeseries smoothing function\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "cartpole = gym.make('CartPole-v1')\n",
    "lunarlander = gym.make('LunarLander-v2')\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T20:50:32.893275Z",
     "start_time": "2018-07-19T20:50:32.580275Z"
    },
    "code_folding": [
     1,
     22
    ]
   },
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class Memory(deque):\n",
    "    \"\"\" Experience Replay Memory class. \"\"\"\n",
    "    size = attr.ib()\n",
    "    minibatch_size = attr.ib()\n",
    "\n",
    "    def append(self, thing):\n",
    "        if len(self) > self.size - 1:\n",
    "            self.popleft()\n",
    "        return super().append(thing)\n",
    "\n",
    "    def sample(self):\n",
    "        batch_size = min(len(self), self.minibatch_size)\n",
    "        data = random.sample(self, batch_size)\n",
    "        states = torch.stack([record[0] for record in data])\n",
    "        actions = torch.tensor([record[1] for record in data], dtype=torch.long)\n",
    "        rewards = torch.tensor([record[2] for record in data], dtype=torch.float)\n",
    "        states_ = torch.stack([record[3] for record in data])\n",
    "        dones = torch.tensor([record[4] for record in data], dtype=torch.long)\n",
    "        return (states, actions, rewards, states_, dones)\n",
    "\n",
    "\n",
    "class ValueDistribution(torch.nn.Module):\n",
    "    def __init__(self, state_shape, action_shape, vmin, vmax, num_atoms=51, num_hidden1_units=64, num_hidden2_units=64):\n",
    "        super().__init__()\n",
    "        self.state_shape = state_shape\n",
    "        self.action_shape = action_shape\n",
    "        self.vmin = vmin\n",
    "        self.vmax = vmax\n",
    "        self.num_atoms = num_atoms\n",
    "        self.atoms = torch.linspace(self.vmin, self.vmax, self.num_atoms)\n",
    "        self.linear1 = nn.Linear(self.state_shape, num_hidden1_units)\n",
    "        self.linear2 = nn.Linear(num_hidden1_units, num_hidden2_units)\n",
    "        self.linear3 = nn.Linear(num_hidden2_units, num_hidden2_units)\n",
    "        self.linear4 = nn.Linear(num_hidden2_units, self.action_shape * self.num_atoms)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\" Return (actions x atoms). \"\"\"\n",
    "        x1 = F.selu(self.linear1(x))\n",
    "        x2 = F.selu(self.linear2(x1))\n",
    "        x3 = F.selu(self.linear3(x2))\n",
    "        x4 = self.linear4(x3).reshape(-1, self.action_shape, self.num_atoms)\n",
    "        out = F.softmax(x4, dim=2)  # (actions x atoms)\n",
    "        if x.dim() == 1:\n",
    "            batch_size = 1\n",
    "        else:\n",
    "            batch_size = x.size(0)\n",
    "        assert out.size() == torch.Size((batch_size, self.action_shape, self.num_atoms))\n",
    "        if hasattr(self, 'monitor'):\n",
    "            self.monitor('x1', x1, track_data=True, track_grad=True)\n",
    "            self.monitor('x2', x2, track_data=True, track_grad=True)\n",
    "            self.monitor('x3', x3, track_data=True, track_grad=True)\n",
    "            self.monitor('x4', x4, track_data=True, track_grad=True)\n",
    "            self.monitor('out', out, track_data=True, track_grad=True)\n",
    "        return out\n",
    "    \n",
    "    def predict_action_values(self, states):\n",
    "        \"\"\" Return (batch-size x actions). \"\"\"\n",
    "        distribution = self.forward(states)\n",
    "        weighted_distribution = distribution * self.atoms\n",
    "        out = weighted_distribution.sum(dim=2).squeeze()  # (batch-size x actions)\n",
    "        dims = states.dim()\n",
    "        assert out.size() == torch.Size((self.action_shape,))\n",
    "        return out\n",
    "        \n",
    "    def get_action(self, state):        \n",
    "        values = self.predict_action_values(state)\n",
    "        action = values.argmax()\n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T19:19:40.302183Z",
     "start_time": "2018-07-19T19:19:40.113459Z"
    }
   },
   "source": [
    "## Vectorizing is terrible/awesome.\n",
    "\n",
    "This is the algo we'll be implementing. \n",
    "\n",
    "![The C51 algorithm](assets/C51-algo.png)\n",
    "\n",
    "Vectorizing this code is *very* important. Even on my lowely macbook, the fully vectorized version of this algorithm that accepts a minibatch runs about *30 times* faster than a naive implementation that's called inside a loop. This cashes out to 1000 training episodes of LunarLander in about 10 minutes, verses five hours. \n",
    "\n",
    "My process for vectoring this code was.. to sort of squint at it. \n",
    "Seriously. I wasn't even sure if I should first generalize it to accept minibatch tensors and then remove the loop, or vice versa. \n",
    "\n",
    "Squinting at it, thought, (and stepping through it line by line in Jupyter a few times), it became clear that the would actually tricky to vectorize: \n",
    "\n",
    "![The bastard lines]](assets/C51-algo-large.png)\n",
    "\n",
    "I decided to take the easy wins first, and first converted the `categorical_loss` function to accept minibatches first. This is straighforward, mostly just reshaping and expanding tensors. Pytorch's `squeeze` and `unsqueeze` methods have fun names and are great for this. \n",
    "\n",
    "Those two lines, though, were bloody horrible. \n",
    "\n",
    "They ended up cashing out into the following dense six lines of python:\n",
    "\n",
    "```python\n",
    "offset_bound = target_net.num_atoms * batch_size - target_net.num_atoms\n",
    "idx_offset = torch.range(0, offset_bound, target_net.num_atoms).unsqueeze(1).expand_as(m)\n",
    "lo_idx = (lo + idx_offset).view(-1).type(torch.long)\n",
    "hi_idx = (hi + idx_offset).view(-1).type(torch.long)\n",
    "lo_component = m.view(-1).index_add(0, lo_idx, (probabilities * (hi - b_j)).view(-1) )\n",
    "hi_component = m.view(-1).index_add(0, hi_idx, (probabilities * (b_j - lo)).view(-1) )\n",
    "m += lo_component.resize_as(m) + hi_component.resize_as(m)       \n",
    "```\n",
    "\n",
    "The main insight is that the `lo` and `hi` tensors contain routing information. They tend look like this:\n",
    "\n",
    "```\n",
    "lo:\n",
    "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "        [2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 10],\n",
    "        [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10]])\n",
    "hi:\n",
    "tensor([[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
    "        [3, 4, 5, 6, 7, 7, 8, 9, 10, 10, 10],\n",
    "        [2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10]])\n",
    "```\n",
    "\n",
    "This is for a three-transition test minibatch. The values are the target indicies for where probability needs to accumulate inside `m` our new probability-mass tensor.\n",
    "\n",
    "Eventually after squinting a lot at the PyTorch docs, I figured out that PyTorch's [`index_add`](https://pytorch.org/docs/stable/tensors.html?highlight=index_add#torch.Tensor.index_add_) method would do the trick. \n",
    "\n",
    "Usings `index_add` requires that all the tensors be unrolled, which is why we need index-offsets. Put it together, and you're done.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T20:50:37.150168Z",
     "start_time": "2018-07-19T20:50:37.029223Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def categorical_vectorized_loss(online_net, target_net, transitions, discount): \n",
    "    states, actions, rewards, states_, dones = transitions\n",
    "    not_dones = (1 - dones).type(torch.FloatTensor)\n",
    "    atoms = target_net.atoms\n",
    "    probabilities = target_net.forward(states_)\n",
    "    Q_x_ = (probabilities * atoms).sum(2)\n",
    "    batch_size = states.shape[0]\n",
    "    assert Q_x_.shape == torch.Size((batch_size, target_net.action_shape)), f'Got: {Q_x_.shape}, expected: {(batch_size, target_net.action_shape)}'\n",
    "    a_star = Q_x_.argmax(dim=1) \n",
    "    assert a_star.shape == torch.Size((batch_size,)), f'Got {a_star.shape}, expected: ((batch_size,))'\n",
    "    \n",
    "    # compute the projected probability:\n",
    "    delta_z = (target_net.vmax - target_net.vmin)/(target_net.num_atoms - 1)    \n",
    "    # select only the probabilities distributions for the a_star actions:\n",
    "    probabilities = probabilities[range(batch_size), a_star]\n",
    "    T_zj = rewards.unsqueeze(1) + discount * atoms * not_dones.unsqueeze(1)\n",
    "    b_j = (T_zj.clamp(target_net.vmin, target_net.vmax) - target_net.vmin) / delta_z  # correct    \n",
    "    lo = b_j.floor()        \n",
    "    hi = b_j.ceil()\n",
    "    m = torch.zeros(batch_size, target_net.num_atoms, dtype=torch.float)\n",
    "    lo_component = torch.zeros_like(m.view(-1))\n",
    "    hi_component = torch.zeros_like(m.view(-1))\n",
    "    # offset will be used for indexing when we flatten the tensors into vectors:\n",
    "    offset_bound = target_net.num_atoms * batch_size - target_net.num_atoms\n",
    "    idx_offset = torch.range(0, offset_bound, target_net.num_atoms).unsqueeze(1).expand_as(m)\n",
    "    lo_idx = (lo + idx_offset).view(-1).type(torch.long)\n",
    "    hi_idx = (hi + idx_offset).view(-1).type(torch.long)\n",
    "    lo_component = m.view(-1).index_add(0, lo_idx, (probabilities * (hi - b_j)).view(-1) )\n",
    "    hi_component = m.view(-1).index_add(0, hi_idx, (probabilities * (b_j - lo)).view(-1) )\n",
    "    m += lo_component.reshape(batch_size, target_net.num_atoms) + hi_component.reshape(batch_size, target_net.num_atoms)\n",
    "    # cross enthropy is Sigma <true> log <unnatural>, so for us is: target log(online)\n",
    "    online_distribution = online_net.forward(states)[range(batch_size), actions]\n",
    "    return -( m * online_distribution.log() ).sum(1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T20:52:12.833754Z",
     "start_time": "2018-07-19T20:52:12.145323Z"
    },
    "code_folding": [
     20,
     52,
     99
    ]
   },
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class CategoricalAgent:\n",
    "    env = attr.ib()\n",
    "    discount = attr.ib(default=0.99)\n",
    "    epsilon_max = attr.ib(default=1.0)\n",
    "    epsilon_min = attr.ib(default=0.01)\n",
    "    annealing_const = attr.ib(default=.001)  # aka Lambda\n",
    "    minibatch_size = attr.ib(default=32)\n",
    "    memory_size = attr.ib(default=int(1e6))\n",
    "    num_episodes = attr.ib(default=1000)  # num of episodes in a training epoch\n",
    "    render_every = attr.ib(default=20)  # set to zero to turn off rendering\n",
    "    update_target_every = attr.ib(default=200)\n",
    "    vmin = attr.ib(default=-10)\n",
    "    vmax = attr.ib(default=10)\n",
    "    num_atoms = attr.ib(default=51)\n",
    "    learning_rate = attr.ib(default=0.000001)\n",
    "    monitor_every = attr.ib(default=50)\n",
    "    logger = attr.ib(default=None)\n",
    "    reward_scaling = attr.ib(default=1.0)\n",
    "    \n",
    "    def __attrs_post_init__(self):\n",
    "        self.steps = 0\n",
    "        state_shape = self.env.observation_space.shape[0]\n",
    "        self.memory = Memory(self.memory_size, self.minibatch_size)\n",
    "        self.action_shape = self.env.action_space.n\n",
    "        self.online_net = ValueDistribution(state_shape=state_shape, action_shape=self.action_shape, vmin=self.vmin, vmax=self.vmax, num_atoms=self.num_atoms)\n",
    "        self.target_net = ValueDistribution(state_shape=state_shape, action_shape=self.action_shape, vmin=self.vmin, vmax=self.vmax, num_atoms=self.num_atoms)\n",
    "        self.target_net.load_state_dict(self.online_net.state_dict())\n",
    "        self.optimizer = torch.optim.Adam(self.online_net.parameters(), lr=self.learning_rate)\n",
    "        self.steps = 0\n",
    "        self.target_net_q_values = []\n",
    "        self.episode_rewards = []\n",
    "        self.training_loss = []\n",
    "        \n",
    "    def render(self, episode):\n",
    "        if self.render_every and episode % self.render_every == 0:\n",
    "            self.env.render()\n",
    "\n",
    "    def training_progress_report(self, episode):\n",
    "        last_ep = self.episode_rewards[-1]\n",
    "        ten_ep_mean = sum(self.episode_rewards[-10:])/len(self.episode_rewards[-10:])\n",
    "        hundred_ep_mean = sum(self.episode_rewards[-100:])/len(self.episode_rewards[-100:])\n",
    "        return f'Ep: {episode} // steps: {self.steps} // last ep reward: {last_ep:.2f} // {min(10, len(self.episode_rewards[-10:]))}-ep mean: {ten_ep_mean:.2f} // {min(100, len(self.episode_rewards[-100:]))}-ep mean: {hundred_ep_mean:.2f}'\n",
    "\n",
    "    def replay(self):\n",
    "        batch = self.memory.sample()\n",
    "        loss = categorical_vectorized_loss(self.online_net, self.target_net, batch, self.discount)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()/self.minibatch_size\n",
    "\n",
    "    def monitor(self):\n",
    "        if not hasattr(self.target_net, 'monitoring'):\n",
    "            return\n",
    "        if self.monitor_every and self.steps % self.monitor_every == 0:\n",
    "            self.target_net.monitoring(True)\n",
    "        else:\n",
    "            self.target_net.monitoring(False)\n",
    "\n",
    "    def train(self):\n",
    "        for episode in range(self.num_episodes):\n",
    "            episode_done = False\n",
    "            episode_reward = 0\n",
    "            episode_loss = 0\n",
    "            state = torch.tensor(self.env.reset(), dtype=torch.float)\n",
    "            self.target_net_q_values.append(self.target_net.predict_action_values(state).max().item())\n",
    "            if self.steps == 0 and self.logger:\n",
    "                self.logger.add_graph(self.target_net, state)\n",
    "            # writer.add_scalar('Target net Q values', self.target_net_q_values[-1], episode)                \n",
    "            while not episode_done:\n",
    "                epsilon = self.epsilon_min + (self.epsilon_max - self.epsilon_min) * math.exp(-self.annealing_const * self.steps)\n",
    "                self.steps += 1                \n",
    "                if random.random() < epsilon:\n",
    "                    action = random.randint(0, self.action_shape-1)\n",
    "                else:\n",
    "                    action = self.online_net.get_action(state).item()\n",
    "                self.render(episode)\n",
    "                self.monitor()\n",
    "                state_, reward, episode_done, _ = self.env.step(action)\n",
    "                reward *= self.reward_scaling\n",
    "                state_ = torch.tensor(state_, dtype=torch.float)\n",
    "                episode_reward += reward\n",
    "                self.memory.append((state, action, reward, state_, episode_done))\n",
    "                state = state_\n",
    "                if self.steps < 2:\n",
    "                    continue\n",
    "                episode_loss += self.replay()\n",
    "\n",
    "                if self.steps % self.update_target_every == 0:\n",
    "                    self.target_net.load_state_dict(self.online_net.state_dict())\n",
    "                if episode_done:\n",
    "                    self.episode_rewards.append(episode_reward)\n",
    "                    self.training_loss.append(episode_loss)\n",
    "                    print(self.training_progress_report(episode), end='\\r', flush=True)\n",
    "                    # writer.add_scalar('train loss', episode_loss, episode)\n",
    "                    # writer.add_scalar('episode reward', episode_reward, episode)                    \n",
    "        self.env.close()\n",
    "\n",
    "    def test(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-19T21:00:08.500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep: 268 // steps: 201013 // last ep reward: -19.48 // 10-ep mean: -28.38 // 100-ep mean: -33.802\r"
     ]
    }
   ],
   "source": [
    "agent = CategoricalAgent(\n",
    "    lunarlander, \n",
    "    learning_rate=0.00003, \n",
    "    monitor_every=0,\n",
    "    num_episodes=1000,\n",
    "    update_target_every=100,  \n",
    "    reward_scaling=.3\n",
    ")\n",
    "agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T20:58:44.148250Z",
     "start_time": "2018-07-19T20:58:43.893566Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x129b5c198>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1296896d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(agent.target_net_q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging\n",
    "\n",
    "Getting this working took a *lot* of debugging time. I went fairly far down a blind alley \n",
    "\n",
    "    - not the exploding gradients: small step size was a blind alley\n",
    "    - not the layer init\n",
    "    - Debugging w. three-armed bandit\n",
    "    - comparing against other implementations?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "266px",
    "width": "268px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
